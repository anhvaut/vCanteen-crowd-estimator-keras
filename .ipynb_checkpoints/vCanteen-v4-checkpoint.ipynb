{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ICANTEEN_TRAIN_PATH = 'image_preprocessor/data/formatted_trainval/icanteen_patches/train/'\n",
    "ICANTEEN_TRAIN_GT_PATH = 'image_preprocessor/data/formatted_trainval/icanteen_patches/train_den/'\n",
    "ICANTEEN_VAL_PATH = 'image_preprocessor/data/formatted_trainval/icanteen_patches/val/'\n",
    "ICANTEEN_VAL_GT_PATH = 'image_preprocessor/data/formatted_trainval/icanteen_patches/val_den/'\n",
    "ICANTEEN_TEST_PATH = 'icanteen_img/test/images/'\n",
    "ICANTEEN_TEST_GT_PATH = 'icanteen_img/test/ground_truth/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_test(path):\n",
    "    print('loading testing dataset...')\n",
    "    img_names = os.listdir(path)\n",
    "    img_num = len(img_names)\n",
    "    img_names.sort()\n",
    "    \n",
    "    data = []\n",
    "    i = 1\n",
    "    for name in img_names:\n",
    "        if name=='.DS_Store':\n",
    "            continue\n",
    "        if i % 50 == 0:\n",
    "            print('loaded:', i, '/', img_num)\n",
    "        img = cv2.imread(path+name,0)\n",
    "        norm_img = (img - 127.5) / 128\n",
    "        data.append(norm_img)\n",
    "        i += 1\n",
    "    print('load data finished')\n",
    "    return data\n",
    "\n",
    "def preprocess_train(img_path, gt_path):\n",
    "    print('loading training dataset...')\n",
    "    img_names = os.listdir(img_path)\n",
    "    img_num = len(img_names)\n",
    "    img_names.sort()\n",
    "\n",
    "    data = []\n",
    "    density = []\n",
    "    count = 1\n",
    "    for name in img_names:\n",
    "        if count % 100 == 0:\n",
    "            print(count, '/', img_num)\n",
    "        count += 1\n",
    "        img = cv2.imread(img_path + name, 0)\n",
    "        img = np.array(img)\n",
    "        norm_img = (img - 127.5) / 128\n",
    "        den = np.loadtxt(open(gt_path + name[:-4] + '.csv'), delimiter = \",\")\n",
    "        den_quarter = np.zeros((int(den.shape[0] / 4), int(den.shape[1] / 4)))\n",
    "        for i in range(len(den_quarter)):\n",
    "            for j in range(len(den_quarter[0])):\n",
    "                for p in range(4):\n",
    "                    for q in range(4):\n",
    "                        den_quarter[i][j] += den[i * 4 + p][j * 4 + q]\n",
    "        data.append(np.reshape(norm_img, [norm_img.shape[0], norm_img.shape[1], 1]))\n",
    "        density.append(np.reshape(den_quarter, [den_quarter.shape[0], den_quarter.shape[1], 1]))\n",
    "    data = np.array(data)\n",
    "    density = np.array(density)\n",
    "    print('load training data finished')\n",
    "    return (data, density)\n",
    "        \n",
    "def get_ground_truth(path, verbose = 0):\n",
    "    if verbose == 1:\n",
    "        print('loading ground truth...')\n",
    "    gt_names = os.listdir(path)\n",
    "    gt_names.sort()\n",
    "    gt = []\n",
    "    i = 1\n",
    "    for file in gt_names:\n",
    "        if file=='.DS_Store':\n",
    "            continue\n",
    "        mat = scipy.io.loadmat(path+file)\n",
    "        gt.append(mat['image_info'][0][0][0][0][1][0][0])\n",
    "        i += 1\n",
    "    if verbose == 1:\n",
    "        print('load ground truth finished')\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, gt_path, verbose = 0, show=False, save=False):\n",
    "    mae = 0\n",
    "    mse = 0\n",
    "    mae_sht = 0\n",
    "    mse_sht = 0\n",
    "    ground_truth = get_ground_truth(gt_path)\n",
    "    pred = []\n",
    "    pred_sht= []\n",
    "    \n",
    "    mcnn = get_MCNN()\n",
    "    mcnn.load_weights('keras_weight/weights.h5')\n",
    "\n",
    "    initial_num = 31\n",
    "    i = 0\n",
    "    for d in data:\n",
    "        inputs = np.reshape(d, [1, d.shape[0], d.shape[1], 1])\n",
    "        outputs = model.predict(inputs)\n",
    "        c_pre = round(np.sum(outputs))\n",
    "        pred.append(c_pre)\n",
    "        sht_pre = round(np.sum(mcnn.predict(inputs)))\n",
    "        pred_sht.append(sht_pre)\n",
    "        if verbose == 1:\n",
    "            print('='*10+'IMG_'+str(i+initial_num)+'.jpg'+'='*10)\n",
    "            print('IMG_'+str(i+initial_num),'vCanteen predicted ', c_pre,'people')\n",
    "            print('IMG_'+str(i+initial_num),'ShanghaiTech predicted ', sht_pre,'people')\n",
    "            print('IMG_'+str(i+initial_num),'Actual',ground_truth[i], 'people')\n",
    "        mae += abs(ground_truth[i]-c_pre)\n",
    "        mse += (ground_truth[i]-c_pre)**2\n",
    "        mae_sht += abs(ground_truth[i]-sht_pre)\n",
    "        mse_sht += (ground_truth[i]-sht_pre)**2\n",
    "        if verbose == 1:\n",
    "            print('ERROR:',abs(ground_truth[i]-c_pre))\n",
    "            print('current vCanteen MAE:',mae/(i+1))\n",
    "            print('current vCanteen MSE:',(mse/(i+1))**0.5)\n",
    "            print('current ShanghaiTech MAE:',mae_sht/(i+1))\n",
    "            print('current ShanghaiTech MSE:',(mse_sht/(i+1))**0.5)\n",
    "\n",
    "        den = outputs.reshape(outputs.shape[1], outputs.shape[2])\n",
    "        img = inputs.reshape(inputs.shape[1], inputs.shape[2])\n",
    "        den_resize = cv2.resize(den, (img.shape[1], img.shape[0]))\n",
    "        if show:\n",
    "            merge = 0.95 * den_resize + 0.05 * img\n",
    "            plt.figure(figsize=(15, 7.5))\n",
    "            plt.imshow(merge, cmap='gray')\n",
    "            plt.title('IMG_'+str(initial_num+i))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.show()\n",
    "            \n",
    "        if save:\n",
    "            den_name = 'heat_'+'IMG_'+str(i+initial_num)+'.png'\n",
    "            plt.imsave('icanteen_heat/'+den_name, den)\n",
    "            print('Finish saving',den_name,'!')\n",
    "        i += 1\n",
    "\n",
    "    print('vCanteen Mean Absolute Error:',mae/len(ground_truth))\n",
    "    print('vCanteen Mean Square Error:',math.sqrt(mse/len(ground_truth)))\n",
    "    print('ShanghaiTech Mean Absolute Error:',mae_sht/len(ground_truth))\n",
    "    print('ShanghaiTech Mean Square Error:',math.sqrt(mse_sht/len(ground_truth)))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(np.arange(1,len(ground_truth)+1),ground_truth, marker='o', label = 'Ground Truth')\n",
    "    plt.plot(np.arange(1,len(ground_truth)+1),pred, marker='o', label = 'vCanteen')\n",
    "    plt.plot(np.arange(1,len(ground_truth)+1),pred_sht, marker='o', label = 'ShanghaiTech')\n",
    "    plt.xticks(np.arange(1,len(ground_truth)+1))\n",
    "    plt.xlabel('Img no.')\n",
    "    plt.ylabel('People')\n",
    "    plt.legend()\n",
    "    plt.title('Head counts Actual vs Predict')\n",
    "    plt.show()\n",
    "    \n",
    "    return (pred, pred_sht, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_data, ground_truth):\n",
    "    mae = 0\n",
    "    mse = 0\n",
    "    i = 0\n",
    "    for d in test_data:\n",
    "        inputs = np.reshape(d, [1, d.shape[0], d.shape[1], 1])\n",
    "        outputs = model.predict(inputs)\n",
    "        c_pre = round(np.sum(outputs))\n",
    "        mae += abs(ground_truth[i]-c_pre)\n",
    "        mse += (ground_truth[i]-c_pre)**2\n",
    "        i += 1\n",
    "        \n",
    "    return (mae, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training dataset...\n",
      "100 / 1035\n",
      "200 / 1035\n",
      "300 / 1035\n",
      "400 / 1035\n",
      "500 / 1035\n",
      "600 / 1035\n",
      "700 / 1035\n",
      "800 / 1035\n",
      "900 / 1035\n",
      "1000 / 1035\n",
      "load training data finished\n",
      "loading training dataset...\n",
      "100 / 135\n",
      "load training data finished\n",
      "loading testing dataset...\n",
      "load data finished\n"
     ]
    }
   ],
   "source": [
    "train, train_den = preprocess_train(ICANTEEN_TRAIN_PATH, ICANTEEN_TRAIN_GT_PATH)\n",
    "val, val_den = preprocess_train(ICANTEEN_VAL_PATH, ICANTEEN_VAL_GT_PATH)\n",
    "data = preprocess_test(ICANTEEN_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def get_MCNN(lr, freeze=False):    \n",
    "    input1 = Input(shape=(None, None, 1)) \n",
    "    \n",
    "    # S\n",
    "    xs = Conv2D(24, kernel_size = (5,5), padding = 'same', activation = 'relu')(input1)   \n",
    "    xs = MaxPooling2D(pool_size = (2,2))(xs)\n",
    "    xs = Conv2D(48, kernel_size = (3,3), padding = 'same', activation = 'relu')(xs)\n",
    "    xs = MaxPooling2D(pool_size = (2,2))(xs)\n",
    "    xs = Conv2D(24, kernel_size = (3,3), padding = 'same', activation = 'relu')(xs)\n",
    "    xs = Conv2D(12, kernel_size = (3,3), padding = 'same', activation = 'relu')(xs)\n",
    "    \n",
    "    # M\n",
    "    xm = Conv2D(20, kernel_size = (7,7), padding = 'same', activation = 'relu')(input1)   \n",
    "    xm = MaxPooling2D(pool_size = (2,2))(xm)\n",
    "    xm = Conv2D(40, kernel_size = (5,5), padding = 'same', activation = 'relu')(xm)\n",
    "    xm = MaxPooling2D(pool_size = (2,2))(xm)\n",
    "    xm = Conv2D(20, kernel_size = (5,5), padding = 'same', activation = 'relu')(xm)\n",
    "    xm = Conv2D(10, kernel_size = (5,5), padding = 'same', activation = 'relu')(xm)\n",
    "    \n",
    "    # L\n",
    "    xl = Conv2D(16, kernel_size = (9,9), padding = 'same', activation = 'relu')(input1)   \n",
    "    xl = MaxPooling2D(pool_size = (2,2))(xl)\n",
    "    xl = Conv2D(32, kernel_size = (7,7), padding = 'same', activation = 'relu')(xl)\n",
    "    xl = MaxPooling2D(pool_size = (2,2))(xl)\n",
    "    xl = Conv2D(16, kernel_size = (7,7), padding = 'same', activation = 'relu')(xl)\n",
    "    xl = Conv2D(8, kernel_size = (7,7), padding = 'same', activation = 'relu')(xl)\n",
    "    \n",
    "    x = concatenate([xm, xs, xl])\n",
    "    out = Conv2D(1, kernel_size = (1,1), padding = 'same')(x)\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    \n",
    "    if freeze:\n",
    "        len_layers = len(model.layers)\n",
    "        for layer in model.layers[:16]:\n",
    "            layer.trainable=False\n",
    "        for layer in model.layers[16:]:\n",
    "            layer.trainable=True\n",
    "        \n",
    "    adam = Adam(lr)\n",
    "    sgd = SGD(lr, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    if freeze:\n",
    "        model.compile(loss='mse', optimizer=adam, metrics=['mse'])\n",
    "    else:\n",
    "        model.compile(loss='mse', optimizer=sgd, metrics=['mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training MCNN with batch size = 1, epochs = 10, learning rate = 0.01\n",
      "test_loss improved from inf to 1099.0\n",
      "start training MCNN with batch size = 1, epochs = 10, learning rate = 0.001\n",
      "start training MCNN with batch size = 1, epochs = 10, learning rate = 0.0001\n",
      "test_loss improved from 1099.0 to 1090.0\n",
      "start training MCNN with batch size = 1, epochs = 20, learning rate = 0.01\n",
      "test_loss improved from 1090.0 to 1046.0\n",
      "start training MCNN with batch size = 1, epochs = 20, learning rate = 0.001\n",
      "start training MCNN with batch size = 1, epochs = 20, learning rate = 0.0001\n",
      "start training MCNN with batch size = 1, epochs = 40, learning rate = 0.01\n",
      "test_loss improved from 1046.0 to 814.0\n",
      "start training MCNN with batch size = 1, epochs = 40, learning rate = 0.001\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "verbose = 0\n",
    "epochs = [10,20,40,80,160,320]\n",
    "learning_rate = [0.01,0.001,0.0001]\n",
    "batch_size = [1,2,4,8,16,32,64]\n",
    "best_lr = 0\n",
    "best_bs = 0\n",
    "best_e = 0\n",
    "\n",
    "best_model = None\n",
    "min_test_mae = math.inf\n",
    "ground_truth = get_ground_truth(ICANTEEN_TEST_GT_PATH)\n",
    "\n",
    "for bs in batch_size:\n",
    "    for e in epochs:\n",
    "        for lr in learning_rate:\n",
    "            K.clear_session()\n",
    "            print('start training MCNN with batch size = {}, epochs = {}, learning rate = {}'.format(bs, e, lr))\n",
    "            model = get_MCNN(lr=lr)\n",
    "            model.fit(train, train_den,validation_data = (val, val_den),\n",
    "                          epochs = e, batch_size = bs, verbose = verbose)\n",
    "            mae, mse = evaluate(model, data, ground_truth)\n",
    "            if mae < min_test_mae:\n",
    "                print('test_loss improved from {} to {}'.format(min_test_mae, mae))\n",
    "                min_test_mae = mae\n",
    "                best_model = model\n",
    "                best_lr = lr\n",
    "                best_bs = bs\n",
    "                best_e = e\n",
    "                \n",
    "print('Best model with lr = {}, epochs = {}, batch size = {}',format(best_lr, best_bs, best_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "verbose = 0\n",
    "epochs = [10,20,40]\n",
    "\n",
    "learning_rate = [0.01,0.001,0.0001]\n",
    "batch_size = [1,2,4,8,16,32,64]\n",
    "best_lr = 0\n",
    "best_bs = 0\n",
    "best_e = 0\n",
    "\n",
    "best_model = None\n",
    "ground_truth = get_ground_truth(ICANTEEN_TEST_GT_PATH)\n",
    "print('='*10, 'Transfer Learning setting')\n",
    "for bs in batch_size:\n",
    "    for e in epochs:\n",
    "        for lr in learning_rate:\n",
    "            K.clear_session()\n",
    "            print('start training MCNN with batch size = {}, epochs = {}, learning rate = {}'.format(bs, e, lr))\n",
    "            model = get_MCNN(freeze = True, lr=lr)\n",
    "            model.load_weights('keras_weight/weights.h5')\n",
    "            model.fit(train, train_den,validation_data = (val, val_den),\n",
    "                          epochs = e, batch_size = bs, verbose = verbose)\n",
    "            mae, mse = evaluate(model, data, ground_truth)\n",
    "            if mae < min_test_mae:\n",
    "                print('test_loss improved from {} to {}'.format(min_test_mae, mae))\n",
    "                min_test_mae = mae\n",
    "                best_model = model\n",
    "print('Best model with lr = {}, epochs = {}, batch size = {}',format(best_lr, best_bs, best_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred, sht_pred, ground_truth = test_model(model, ICANTEEN_TEST_GT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
